{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b00b4a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "import numpy as np\n",
    "from captum.attr import IntegratedGradients, Saliency, Deconvolution, InputXGradient, GuidedBackprop, NoiseTunnel, IntegratedGradients, Occlusion, GradientShap, FeatureAblation, FeaturePermutation\n",
    "import os        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30cfd89e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "attribution_methods = {\n",
    "    'Saliency': Saliency,\n",
    "    'NoiseTunnel_Saliency': lambda model: NoiseTunnel(Saliency(model)),\n",
    "    'Deconvolution': Deconvolution,\n",
    "    'InputXGradient': InputXGradient,\n",
    "    'GuidedBackprop': GuidedBackprop,\n",
    "    'GradientShap': GradientShap,\n",
    "    'Occlusion': Occlusion,\n",
    "    'IntegratedGradients': IntegratedGradients,\n",
    "    'NoiseTunnel_Deconvolution': lambda model: NoiseTunnel(Deconvolution(model)),\n",
    "    'NoiseTunnel_InputXGradient': lambda model: NoiseTunnel(InputXGradient(model)),\n",
    "    'FeatureAblation': FeatureAblation,\n",
    "    'FeaturePermutation': FeaturePermutation\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e7c85e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "num_classes = 10\n",
    "batch_size = 32\n",
    "image_size = 224\n",
    "\n",
    "device = torch.device('cpu')\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((image_size, image_size)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Custom sorting to ensure numerical order if filenames don't have leading zeros\n",
    "test_dataset = datasets.ImageFolder(root=f'coco200_perclass', transform=transform)\n",
    "test_dataset.samples.sort(key=lambda x: int(os.path.splitext(os.path.basename(x[0]))[0].replace('im', '')))\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "959c1279",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations\n",
    "\n",
    "# List of models\n",
    "models = ['resnet50', 'alexnet', 'convnext', 'vgg19', \"resnet18\", \"vgg16\", \"vit\", \"vit_ssl\", \"resnet_ssl\", \"efficientnet\", \"swin\"]\n",
    "\n",
    "# Initialize L2 similarity dictionary\n",
    "l2_similarities = {}\n",
    "\n",
    "for method_name in attribution_methods.keys():\n",
    "    print(method_name)\n",
    "    l2_similarities[method_name] = {}\n",
    "    \n",
    "    for model1, model2 in combinations(models, 2):\n",
    "        \n",
    "        l2_similarities[method_name][(model1, model2)] = []\n",
    "        \n",
    "    for i in range(len(test_dataset)):\n",
    "        # Load attribution maps for all models\n",
    "        attr_maps = {\n",
    "            model: np.load(f\"./attribution_maps/{model}/{method_name}/image_{i}.npy\") \n",
    "            for model in models\n",
    "        }\n",
    "        \n",
    "        # Compute L2 similarities for all model pairs\n",
    "        for model1, model2 in combinations(models, 2):\n",
    "            epsilon = 1e-8  # Small positive value to prevent division by zero\n",
    "            l2_sim = 1 / (np.linalg.norm(attr_maps[model1] - attr_maps[model2]) + epsilon)    \n",
    "\n",
    "            l2_similarities[method_name][(model1, model2)].append(l2_sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12dbaf35",
   "metadata": {},
   "outputs": [],
   "source": [
    "from six.moves import cPickle as pickle \n",
    "def save_dict(di_, filename_):\n",
    "    with open(filename_, 'wb') as f:\n",
    "        pickle.dump(di_, f)\n",
    "\n",
    "save_dict(l2_similarities, './all_similarities.pkl')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
